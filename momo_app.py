import streamlit as st
import pandas as pd
import time
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
from bs4 import BeautifulSoup
from io import BytesIO

# === 1. çˆ¬èŸ²é©…å‹•è¨­å®š (é›²ç«¯å°ˆç”¨ç‰ˆ) ===
def get_driver():
    chrome_options = Options()
    # é—œéµï¼šé›²ç«¯ä¸»æ©Ÿæ²’æœ‰è¢å¹•ï¼Œå¿…é ˆé–‹å•Ÿ headless (ç„¡é ­æ¨¡å¼)
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # è‡ªå‹•åˆ¤æ–·ç’°å¢ƒå®‰è£ Chrome
    try:
        # å„ªå…ˆå˜—è©¦å®‰è£ Chromium (é©åˆ Streamlit Cloud Linux ç’°å¢ƒ)
        service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
    except:
        # å‚™ç”¨ï¼šå˜—è©¦å®‰è£ä¸€èˆ¬ Chrome (é©åˆæœ¬åœ°æ¸¬è©¦)
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
    return driver

# === 2. çˆ¬èŸ²æ ¸å¿ƒé‚è¼¯ ===
def run_momo_spider(brand_name, max_pages):
    driver = get_driver()
    all_products = []
    seen_ids = set()
    
    status_text = st.empty() 
    progress_bar = st.progress(0)

    try:
        for page in range(1, max_pages + 1):
            status_text.text(f"â³ æ­£åœ¨æŠ“å–ç¬¬ {page} / {max_pages} é ï¼Œè«‹ç¨å€™...")
            progress_bar.progress(int((page / max_pages) * 100))
            
            url = f"https://www.momoshop.com.tw/search/searchShop.jsp?keyword={brand_name}&searchType=1&curPage={page}&_isFuzzy=0&showType=chessboardType"
            driver.get(url)
            time.sleep(1)
            
            # æ»¾å‹•é é¢
            for i in range(5):
                driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(0.5)
            
            soup = BeautifulSoup(driver.page_source, "html.parser")
            links = soup.select("a[href*='GoodsDetail.jsp']")
            
            for link in links:
                try:
                    href = link.get('href', '')
                    if href.startswith('/'):
                        full_url = "https://www.momoshop.com.tw" + href
                    else:
                        full_url = href

                    id_match = re.search(r'i_code=(\d+)', href)
                    if not id_match: continue
                    i_code = id_match.group(1)

                    if i_code in seen_ids: continue
                    seen_ids.add(i_code)

                    product_name = ""
                    if not product_name: product_name = link.get('title', '').strip()
                    if not product_name:
                        img_tag = link.select_one('img')
                        if img_tag: product_name = img_tag.get('alt', '').strip() or img_tag.get('title', '').strip()
                    if not product_name:
                        title_tag = link.select_one('.prdName') or link.select_one('.goodsName')
                        if title_tag: product_name = title_tag.text.strip()

                    if not product_name: continue

                    model_match = re.search(r'([A-Z]{2,}-\w+)', product_name, re.IGNORECASE)
                    model_number = model_match.group(1) if model_match else ""

                    price = "0"
                    sales = "0"
                    
                    container = link.find_parent('li')
                    if container:
                        price_tag = container.select_one('.price') or container.select_one('.money') or container.select_one('b')
                        if price_tag: price = re.sub(r'[^\d]', '', price_tag.text)
                        
                        sales_tag = container.select_one('.totalSales')
                        if sales_tag: sales = sales_tag.text.replace('ç¸½éŠ·é‡', '').replace('>', '').strip()
                    
                    all_products.append({
                        "å“ç‰Œåç¨±": brand_name,
                        "ç”¢å“åç¨±": product_name,
                        "ç”¢å“å‹è™Ÿ": model_number,
                        "åƒ¹æ ¼": price,
                        "ç”¢å“éŠ·é‡": sales,
                        "å•†å“é€£çµ": full_url
                    })

                except Exception:
                    continue
            
            time.sleep(1)

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        driver.quit()
        status_text.text("âœ… æŠ“å–å®Œæˆï¼")
        progress_bar.progress(100)
        
    return all_products

# === 3. ç¶²é ä»‹é¢è¨­è¨ˆ ===
st.set_page_config(page_title="Momo å“ç‰Œçˆ¬èŸ²", page_icon="ğŸ›’")
st.title("ğŸ›’ Momo å“ç‰Œå•†å“çˆ¬èŸ²")
st.markdown("è¼¸å…¥å“ç‰Œï¼Œè‡ªå‹•æŠ“å–åƒ¹æ ¼èˆ‡éŠ·é‡ï¼Œä¸¦ä¸‹è¼‰ Excel è¡¨æ ¼ã€‚")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    brand_input = st.text_input("è¼¸å…¥å“ç‰Œåç¨±", value="è¼è‘‰")
    pages_input = st.slider("æŠ“å–é æ•¸", 1, 10, 2)
    st.info("é›²ç«¯ç‰ˆè«‹è€å¿ƒç­‰å¾…ï¼Œé€Ÿåº¦æœƒæ¯”æœ¬æ©Ÿç¨æ…¢ã€‚")
    start_btn = st.button("ğŸš€ é–‹å§‹æŠ“å–", type="primary")

st.divider()

if start_btn:
    if not brand_input:
        st.warning("è«‹è¼¸å…¥å“ç‰Œåç¨±ï¼")
    else:
        with st.spinner('æ­£åœ¨å•Ÿå‹•é›²ç«¯çˆ¬èŸ²...è«‹ç¨å€™ (ç´„éœ€ 20-40 ç§’)'):
            data = run_momo_spider(brand_input, pages_input)
        
        if data:
            df = pd.DataFrame(data)
            cols = ["å“ç‰Œåç¨±", "ç”¢å“åç¨±", "ç”¢å“å‹è™Ÿ", "åƒ¹æ ¼", "ç”¢å“éŠ·é‡", "å•†å“é€£çµ"]
            df = df[cols]
            
            st.success(f"æˆåŠŸï¼å…±æŠ“å– {len(df)} ç­†è³‡æ–™ã€‚")
            st.dataframe(df)
            
            # Excel ä¸‹è¼‰
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            excel_data = output.getvalue()
            
            st.download_button(
                label="ğŸ“¥ é»æ“Šä¸‹è¼‰ Excel æª”æ¡ˆ",
                data=excel_data,
                file_name=f"{brand_input}_Momo_{timestamp}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary"
            )
        else:
            st.error("æœªæŠ“åˆ°è³‡æ–™ã€‚")